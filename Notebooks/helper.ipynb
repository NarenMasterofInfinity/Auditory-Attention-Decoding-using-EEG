{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a439406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "\n",
    "import os\n",
    "from gammatone.filters import centre_freqs, make_erb_filters, erb_filterbank\n",
    "\n",
    "PREPROC_DIR = \"/home/naren-root/Documents/FYP/AAD/Notebooks/Dataset/DATA_preproc/\"\n",
    "FIG_DIR = Path(\"figures\"); FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "021b341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unwrap_1d(x):\n",
    "    x = np.asarray(x)\n",
    "    if x.dtype == object:\n",
    "        for el in x.flat:\n",
    "            arr = np.asarray(el)\n",
    "            if arr.size:\n",
    "                x = arr\n",
    "                break\n",
    "        else:\n",
    "            return np.array([], dtype=float)\n",
    "    x = np.array(x, dtype=float).squeeze()\n",
    "    if x.ndim > 1:\n",
    "        x = x.mean(axis=0)\n",
    "    return x\n",
    "\n",
    "def _get_fs(mat):\n",
    "    return float(np.array(mat[\"data\"].fsample.eeg))  # 64 Hz in your files\n",
    "\n",
    "def _get_trial_count(mat):\n",
    "    return int(np.asarray(mat[\"data\"].eeg).shape[0])\n",
    "\n",
    "def _get_trial_eeg(mat, i):\n",
    "    arr = np.asarray(mat[\"data\"].eeg)[i]   # (time, n_chan)\n",
    "    arr = np.array(arr, dtype=float)\n",
    "    assert arr.ndim == 2\n",
    "    return arr.T  # -> (n_chan, time)\n",
    "\n",
    "def _get_trial_labels(mat, i):\n",
    "    labels = np.asarray(mat[\"data\"].dim.chan.eeg)[i]  # (n_chan,) object\n",
    "    return [str(x) for x in labels.tolist()]\n",
    "\n",
    "def _get_trial_env(mat, i, which):\n",
    "    if not hasattr(mat[\"data\"], which):\n",
    "        return None\n",
    "    raw = np.asarray(getattr(mat[\"data\"], which))[i]\n",
    "    return _unwrap_1d(raw)\n",
    "\n",
    "def _get_trial_att_events(mat, i):\n",
    "    \"\"\"Return (samples, values) from data.event.eeg[i], if present.\n",
    "       values expected to be 1 or 2 (attended stream id).\"\"\"\n",
    "    ev_all = getattr(mat[\"data\"].event, \"eeg\", None)\n",
    "    if ev_all is None:\n",
    "        return None, None\n",
    "    ev_i = np.asarray(ev_all)[i]\n",
    "    if not hasattr(ev_i, \"_fieldnames\"):\n",
    "        return None, None\n",
    "    samples = getattr(ev_i, \"sample\", None)\n",
    "    values  = getattr(ev_i, \"value\", None)\n",
    "    if samples is None or values is None:\n",
    "        return None, None\n",
    "    samples = np.atleast_1d(np.array(samples, dtype=int).squeeze())\n",
    "    values  = np.atleast_1d(np.array(values, dtype=int).squeeze())\n",
    "    if samples.size != values.size:\n",
    "        m = min(samples.size, values.size)\n",
    "        samples, values = samples[:m], values[:m]\n",
    "    return samples, values\n",
    "\n",
    "def _build_att_mask_trial(n_t, samples, values):\n",
    "    \"\"\"\n",
    "    Per-sample attention id for a single trial:\n",
    "      0 = unknown, 1 = wavA attended, 2 = wavB attended.\n",
    "    MATLAB 'samples' are 1-based; convert to 0-based.\n",
    "    \"\"\"\n",
    "    att = np.zeros(n_t, dtype=np.uint8)\n",
    "    if samples is None or values is None or samples.size == 0:\n",
    "        return att\n",
    "    samp0 = np.clip(samples - 1, 0, n_t - 1)\n",
    "    order = np.argsort(samp0)\n",
    "    samp0, values = samp0[order], values[order]\n",
    "    for k, s in enumerate(samp0):\n",
    "        v = values[k] if values[k] in (1, 2) else 0\n",
    "        e = samp0[k + 1] if k + 1 < samp0.size else n_t\n",
    "        att[s:e] = v\n",
    "    return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e47c9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject(preproc_dir, subj_id, drop_exg=True):\n",
    "    preproc_dir = Path(preproc_dir)\n",
    "    candidates = [\n",
    "        preproc_dir / f\"S{subj_id}_data_preproc.mat\",\n",
    "        preproc_dir / f\"S{subj_id:02d}_data_preproc.mat\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            mat_path = p\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No file for subject {subj_id} in {preproc_dir}\")\n",
    "\n",
    "    mat = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)\n",
    "    fs = _get_fs(mat)\n",
    "    n_trials = _get_trial_count(mat)\n",
    "\n",
    "    eeg_trials, labels_trials = [], []\n",
    "    envA_trials, envB_trials = [], []\n",
    "    attmask_trials, lens = [], []\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        eeg_i = _get_trial_eeg(mat, i)               # (n_ch, n_t)\n",
    "        labs_i = _get_trial_labels(mat, i)\n",
    "        A_i = _get_trial_env(mat, i, \"wavA\")\n",
    "        B_i = _get_trial_env(mat, i, \"wavB\")\n",
    "        n_t = eeg_i.shape[1]\n",
    "\n",
    "        if A_i is not None and A_i.size and A_i.size != n_t:\n",
    "            A_i = resample(A_i, n_t)\n",
    "        if B_i is not None and B_i.size and B_i.size != n_t:\n",
    "            B_i = resample(B_i, n_t)\n",
    "\n",
    "        samples, values = _get_trial_att_events(mat, i)\n",
    "        att_i = _build_att_mask_trial(n_t, samples, values)\n",
    "\n",
    "        eeg_trials.append(eeg_i)\n",
    "        labels_trials.append(labs_i)\n",
    "        envA_trials.append(A_i if A_i is not None and A_i.size else None)\n",
    "        envB_trials.append(B_i if B_i is not None and B_i.size else None)\n",
    "        attmask_trials.append(att_i)\n",
    "        lens.append(n_t)\n",
    "\n",
    "    ch_names = labels_trials[0]\n",
    "    if drop_exg:\n",
    "        keep = [not nm.upper().startswith(\"EXG\") for nm in ch_names]\n",
    "        ch_names = [nm for nm, k in zip(ch_names, keep) if k]\n",
    "        eeg_trials = [x[keep, :] for x in eeg_trials]\n",
    "\n",
    "    eeg = np.concatenate(eeg_trials, axis=1)\n",
    "    T = eeg.shape[1]\n",
    "\n",
    "    def _concat_env_fixed(env_list, lens):\n",
    "        parts = []\n",
    "        for env, n_t in zip(env_list, lens):\n",
    "            if env is None or env.size == 0:\n",
    "                parts.append(np.zeros(n_t, dtype=float))\n",
    "            else:\n",
    "                parts.append(env)\n",
    "        return np.concatenate(parts) if parts else None\n",
    "\n",
    "    envA = _concat_env_fixed(envA_trials, lens)\n",
    "    envB = _concat_env_fixed(envB_trials, lens)\n",
    "    attmask = np.concatenate(attmask_trials) if attmask_trials else np.zeros(T, dtype=np.uint8)\n",
    "\n",
    "    return dict(\n",
    "        fs=fs,\n",
    "        ch_names=ch_names,\n",
    "        eeg=eeg,\n",
    "        envA=envA,            \n",
    "        envB=envB,            # Audio 2 (wavB)\n",
    "        attmask=attmask,      # 0/1/2 per-sample\n",
    "        lengths=lens,\n",
    "        subj_id=subj_id,\n",
    "        has_two_streams=(envA is not None and envB is not None and (envA.any() or envB.any())),\n",
    "        path=str(mat_path),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa38e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lp_filter(y, fs, cutoff_hz, order = 4):\n",
    "    if cutoff_hz is None or cutoff_hz <= 0:\n",
    "        return y\n",
    "    nyq = fs / 2.0\n",
    "    cutoff = min(cutoff_hz, nyq * 0.99)\n",
    "    b, a = signal.butter(order, cutoff / nyq)\n",
    "    return signal.filtfilt(b, a, y)\n",
    "\n",
    "def _resample_to(y, fs_in, fs_out):\n",
    "    if fs_out is None or fs_out == fs_in:\n",
    "        return y, fs_in\n",
    "    # robust poly-phase resampling\n",
    "    from fractions import Fraction\n",
    "    frac = Fraction(fs_out, fs_in).limit_denominator(1000)\n",
    "    up, down = frac.numerator, frac.denominator\n",
    "    y2 = signal.resample_poly(y, up, down)\n",
    "    return y2, fs_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4d49474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gammatone_hilbert_envelope(audio, fs, *, num_bands = 32, fmin = 50.0, fmax=None, compress = \"pow\", compress_exp = 0.6, aggregate = \"sum\", lowpass_hz = 8.0, target_fs = None, normalize = \"unit\", return_bands = False):\n",
    "   \n",
    "    x = np.asarray(audio, dtype=float).ravel()\n",
    "\n",
    "    # If `audio` seems to be an envelope already (e.g., 64 Hz), do a simple path\n",
    "    if fs < 1000 or centre_freqs is None or make_erb_filters is None or erb_filterbank is None:\n",
    "        env = np.abs(signal.hilbert(x))\n",
    "        env = _lp_filter(env, fs, lowpass_hz)\n",
    "        env, fs_env = _resample_to(env, fs, target_fs)\n",
    "        if normalize == \"unit\":\n",
    "            m = np.max(np.abs(env))\n",
    "            if m > 0:\n",
    "                env = env / (m + 1e-12)\n",
    "        elif normalize == \"zscore\":\n",
    "            env = (env - env.mean()) / (env.std() + 1e-12)\n",
    "        meta = {\"fs\": fs_env, \"cf\": None, \"band_envs\": None, \"aggregate\": \"simple\", \"compress\": \"none\"}\n",
    "        return env.astype(float), meta\n",
    "\n",
    "    # Proper gammatone filterbank\n",
    "    if fmax is None:\n",
    "        fmax = min(0.45 * fs, fs / 2.0)\n",
    "    cf = centre_freqs(fs, num_bands, fmin)\n",
    "    cf = cf[cf <= fmax]\n",
    "    if cf.size == 0:\n",
    "        raise ValueError(\"No center frequencies within [fmin, fmax].\")\n",
    "\n",
    "    fcoefs = make_erb_filters(fs, cf)\n",
    "    y = erb_filterbank(x, fcoefs)            # shape: (n_bands, T)\n",
    "    band_envs = np.abs(signal.hilbert(y, axis=-1))\n",
    "\n",
    "    # Compression\n",
    "    if compress == \"pow\":\n",
    "        band_envs = np.power(band_envs, float(compress_exp))\n",
    "    elif compress == \"log\":\n",
    "        band_envs = np.log1p(band_envs)\n",
    "\n",
    "    # Aggregate\n",
    "    if band_envs.ndim == 1:\n",
    "        agg = band_envs\n",
    "    else:\n",
    "        if aggregate == \"sum\":\n",
    "            agg = band_envs.sum(axis=0)\n",
    "        elif aggregate == \"rms\":\n",
    "            agg = np.sqrt((band_envs ** 2).mean(axis=0))\n",
    "        else:  # mean\n",
    "            agg = band_envs.mean(axis=0)\n",
    "\n",
    "    # Low-pass smoothing and (optional) resample to target_fs\n",
    "    agg = _lp_filter(agg, fs, lowpass_hz)\n",
    "    env, fs_env = _resample_to(agg, fs, target_fs)\n",
    "\n",
    "    # Final normalization\n",
    "    if normalize == \"unit\":\n",
    "        m = np.max(np.abs(env))\n",
    "        if m > 0:\n",
    "            env = env / (m + 1e-12)\n",
    "    elif normalize == \"zscore\":\n",
    "        env = (env - env.mean()) / (env.std() + 1e-12)\n",
    "\n",
    "    meta = {\"fs\": fs_env, \"cf\": cf, \"band_envs\": band_envs if return_bands else None,\n",
    "                            \"aggregate\": aggregate, \"compress\": compress}\n",
    "    return env.astype(float), meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6b1d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _unique_path(prefix: str) -> Path:\n",
    "    p = FIG_DIR / f\"{prefix}.png\"\n",
    "    k = 1\n",
    "    while p.exists():\n",
    "        p = FIG_DIR / f\"{prefix}_{k}.png\"\n",
    "        k += 1\n",
    "    return p\n",
    "\n",
    "def plot_env_overlay(audio: np.ndarray,\n",
    "                     fs_audio: float,\n",
    "                     env: np.ndarray,\n",
    "                     meta: dict,\n",
    "                     t_start: float = 0.0,\n",
    "                     t_end: float | None = None,\n",
    "                     audio_norm: str = \"none\",   # \"none\" | \"zscore\"\n",
    "                     env_norm: str = \"unit\",     # \"unit\" | \"zscore\" | \"none\"\n",
    "                     title: str | None = None,\n",
    "                     out_path: str | None = None) -> str:\n",
    "    if t_end is None:\n",
    "        t_end = max(len(audio)/fs_audio, len(env)/float(meta.get(\"fs\", fs_audio)))\n",
    "    fs_env = float(meta.get(\"fs\", fs_audio))\n",
    "\n",
    "    i0 = max(0, int(np.floor(t_start * fs_audio)))\n",
    "    i1 = min(len(audio), int(np.ceil(t_end * fs_audio)))\n",
    "    j0 = max(0, int(np.floor(t_start * fs_env)))\n",
    "    j1 = min(len(env), int(np.ceil(t_end * fs_env)))\n",
    "\n",
    "    a = np.asarray(audio[i0:i1], float)\n",
    "    e = np.asarray(env[j0:j1], float)\n",
    "    t_a = np.arange(i0, i1) / fs_audio\n",
    "    t_e = np.arange(j0, j1) / fs_env\n",
    "\n",
    "    if audio_norm == \"zscore\":\n",
    "        a = (a - a.mean()) / (a.std() + 1e-12)\n",
    "    if env_norm == \"unit\":\n",
    "        m = np.max(np.abs(e));  e = e / (m + 1e-12) if m > 0 else e\n",
    "    elif env_norm == \"zscore\":\n",
    "        e = (e - e.mean()) / (e.std() + 1e-12)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(t_a, a, lw=0.8, label=\"audio\")\n",
    "    plt.plot(t_e, e, lw=1.2, label=\"envelope\")\n",
    "    plt.xlabel(\"Time (s)\"); plt.ylabel(\"Amplitude\")\n",
    "    plt.title(title or \"Audio + Envelope\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = str(_unique_path(f\"env_overlay_{int(t_start*1000)}ms_{int(t_end*1000)}ms\"))\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=200); plt.close()\n",
    "    return out_path\n",
    "\n",
    "def plot_env_bands(meta: dict,\n",
    "                   t_start: float = 0.0,\n",
    "                   t_end: float | None = None,\n",
    "                   vmin: float | None = None,\n",
    "                   vmax: float | None = None,\n",
    "                   title: str | None = None,\n",
    "                   out_path: str | None = None) -> str:\n",
    "    band_envs = meta.get(\"band_envs\", None)\n",
    "    fs_env = float(meta.get(\"fs\", 0))\n",
    "    cf = meta.get(\"cf\", None)\n",
    "    if band_envs is None or fs_env <= 0:\n",
    "        raise ValueError(\"meta must contain 'band_envs' and 'fs' to plot bands\")\n",
    "\n",
    "    B, T = band_envs.shape\n",
    "    if t_end is None:\n",
    "        t_end = T / fs_env\n",
    "    j0 = max(0, int(np.floor(t_start * fs_env)))\n",
    "    j1 = min(T, int(np.ceil(t_end * fs_env)))\n",
    "    be = np.asarray(band_envs[:, j0:j1], float)\n",
    "    t = np.arange(j0, j1) / fs_env\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    extent = [t[0], t[-1] if t.size else t_end, (cf[0] if cf is not None else 1), (cf[-1] if cf is not None else B)]\n",
    "    plt.imshow(be[::-1, :], aspect=\"auto\", extent=[extent[0], extent[1], extent[2], extent[3]],\n",
    "               vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(label=\"Envelope\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Center frequency (Hz)\" if cf is not None else \"Band index\")\n",
    "    plt.title(title or \"Per-band envelopes\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = str(_unique_path(f\"env_bands_{int(t_start*1000)}ms_{int(t_end*1000)}ms\"))\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=200); plt.close()\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24485176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_to_64(eeg, ch_names=None):\n",
    "    X = np.asarray(eeg, float)\n",
    "    n_ch = X.shape[0]\n",
    "    if n_ch <= 64:\n",
    "        return X, (ch_names if ch_names is not None else [f\"Ch{i+1}\" for i in range(n_ch)]), np.arange(n_ch)\n",
    "\n",
    "    if ch_names is not None:\n",
    "        bad_prefixes = (\"EXG\", \"MISC\", \"AUX\", \"STATUS\", \"TRIG\")\n",
    "        bad_contains = (\"EOG\", \"ECG\", \"EMG\")\n",
    "        keep_idx = []\n",
    "        for i, nm in enumerate(ch_names):\n",
    "            nm_u = str(nm).upper()\n",
    "            if any(nm_u.startswith(p) for p in bad_prefixes): continue\n",
    "            if any(k in nm_u for k in bad_contains): continue\n",
    "            keep_idx.append(i)\n",
    "        if len(keep_idx) >= 64:\n",
    "            keep_idx = keep_idx[:64]\n",
    "        else:\n",
    "            rest = [i for i in range(n_ch) if i not in keep_idx]\n",
    "            keep_idx = (keep_idx + rest)[:64]\n",
    "    else:\n",
    "        keep_idx = list(range(64))\n",
    "\n",
    "    keep_idx = np.asarray(keep_idx, int)\n",
    "    X64 = X[keep_idx, :]\n",
    "    ch64 = [ch_names[i] for i in keep_idx] if ch_names is not None else [f\"Ch{i+1}\" for i in range(64)]\n",
    "    return X64, ch64, keep_idx\n",
    "\n",
    "\n",
    "def subject_eeg_audio(preproc_dir,\n",
    "                       subj_id,\n",
    "                       num_bands=64,\n",
    "                       fmin=50.0,\n",
    "                       fmax=None,\n",
    "                       lowpass_hz=8.0,\n",
    "                       normalize=\"unit\"):\n",
    "    \"\"\"\n",
    "    Returns EEG (T x C), attended envelope (T,), fs, and per-sample 'A'/'B' labels.\n",
    "    Uses your gammatone_hilbert_envelope; trims 66→64 channels cleanly.\n",
    "    \"\"\"\n",
    "    D = load_subject(preproc_dir, subj_id, drop_exg=True)\n",
    "\n",
    "    fs = float(D[\"fs\"])\n",
    "    eeg = np.asarray(D[\"eeg\"], float)            # (n_ch, T)\n",
    "    ch_names = D.get(\"ch_names\", None)\n",
    "\n",
    "    eeg, ch_names64, idx64 = _clean_to_64(eeg, ch_names)\n",
    "    \n",
    "    T = eeg.shape[1]\n",
    "    att = np.asarray(D[\"attmask\"], np.uint8)\n",
    "    wavA = np.asarray(D[\"envA\"], float) if D[\"envA\"] is not None else np.zeros(T, float)\n",
    "    wavB = np.asarray(D[\"envB\"], float) if D[\"envB\"] is not None else np.zeros(T, float)\n",
    "\n",
    "    def _env(x):\n",
    "        env, meta = gammatone_hilbert_envelope(\n",
    "            x, fs,\n",
    "            num_bands=num_bands, fmin=fmin, fmax=fmax,\n",
    "            compress=\"pow\", compress_exp=0.6,\n",
    "            aggregate=\"sum\", lowpass_hz=lowpass_hz,\n",
    "            target_fs=fs, normalize=normalize, return_bands=False,\n",
    "        )\n",
    "        if env.size != T:\n",
    "            env = signal.resample(env, T)\n",
    "        return env.astype(float)\n",
    "\n",
    "    envA = _env(wavA)\n",
    "    envB = _env(wavB)\n",
    "\n",
    "    env_att = np.where(att == 1, envA, np.where(att == 2, envB, 0.0)).astype(float)\n",
    "    att_AB  = np.where(att == 1, \"A\", np.where(att == 2, \"B\", \"U\")).astype(\"<U1\")\n",
    "\n",
    "    eeg_TxC = eeg.T\n",
    "    return eeg_TxC, env_att, fs, att_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52fec8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5', 'FC3', 'FC1', 'C1', 'C3', 'C5', 'T7', 'TP7', 'CP5', 'CP3', 'CP1', 'P1', 'P3', 'P5', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Iz', 'Oz', 'POz', 'Pz', 'CPz', 'Fpz', 'Fp2', 'AF8', 'AF4', 'AFz', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCz', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', 'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'P10', 'PO8', 'PO4', 'O2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  9.70947347,  27.700268  ,  28.42683385, ...,  -6.03082454,\n",
       "         -34.35721669, -33.96078393],\n",
       "        [  4.49293742,  27.2494236 ,  24.95064359, ...,  -4.60977458,\n",
       "         -29.91686625, -30.8138056 ],\n",
       "        [ 10.34741619,  31.41075145,  29.21696963, ...,  -6.62789446,\n",
       "         -33.16222181, -36.59362892],\n",
       "        ...,\n",
       "        [ -9.3691818 ,   6.88691982,   1.0286609 , ...,   0.54570865,\n",
       "           6.39622434,   6.18335204],\n",
       "        [-12.39941793,   3.87620143,  -3.27677883, ...,  -0.99939222,\n",
       "           2.42031908,   2.80503614],\n",
       "        [-11.26664088,   1.86334054,  -2.47354118, ...,   2.25381339,\n",
       "           7.16669159,   6.71865936]], shape=(192000, 64)),\n",
       " array([0.38223552, 0.26540759, 0.16863371, ..., 0.2134771 , 0.21982443,\n",
       "        0.23109459], shape=(192000,)),\n",
       " 64.0,\n",
       " array(['B', 'B', 'B', ..., 'A', 'A', 'A'], shape=(192000,), dtype='<U1'))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_eeg_audio(PREPROC_DIR, 1, num_bands = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df3372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f961b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e240e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5788ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65d882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdc1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e141a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25366631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e875018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2103a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dfd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff2322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
